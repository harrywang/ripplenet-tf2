{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(555)\n",
    "DATASET = 'movie'  # or 'book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news dataset has not been included yet\n",
    "RATING_FILE_NAME = dict({'movie': 'movie_ratings.dat', 'book': 'book_ratings.csv', 'news': 'ratings.txt'})\n",
    "\n",
    "# different rating files have different separators\n",
    "SEP = dict({'movie': '::', 'book': ';', 'news': '\\t'})\n",
    "\n",
    "THRESHOLD = dict({'movie': 4, 'book': 0, 'news': 0})\n",
    "\n",
    "# whether to skip the heading line in file\n",
    "SKIP_LINE = dict({'movie': 0, 'book': 1, 'news': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_id2index = dict()\n",
    "item_index_old2new = dict()\n",
    "relation_id2index = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_index2entity_id_rehashed.txt maps the id in movie and book dataset\n",
    "# to the kg satori id\n",
    "def read_item_index_to_entity_id_file():\n",
    "    file = 'data/' + DATASET + '/item_index2entity_id_rehashed.txt'\n",
    "    print('reading item index to entity id file: ' + file + ' ...')\n",
    "    i = 0\n",
    "    for line in open(file, encoding='utf-8').readlines():\n",
    "        item_index = line.strip().split('\\t')[0]  # item id from the movie dataset\n",
    "        satori_id = line.strip().split('\\t')[1]  # satori id from the kg\n",
    "        item_index_old2new[item_index] = i\n",
    "        entity_id2index[satori_id] = i\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "reading item index to entity id file: data/movie/item_index2entity_id_rehashed.txt ...\n"
    }
   ],
   "source": [
    "read_item_index_to_entity_id_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('0', 0),\n ('1', 1),\n ('2', 2),\n ('3', 3),\n ('4', 4),\n ('5', 5),\n ('6', 6),\n ('7', 7),\n ('8', 8),\n ('9', 9),\n ('10', 10),\n ('11', 11),\n ('12', 12),\n ('13', 13),\n ('14', 14),\n ('15', 15),\n ('16', 16),\n ('17', 17),\n ('18', 18),\n ('19', 19)]"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "list(entity_id2index.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('1', 0),\n ('2', 1),\n ('3', 2),\n ('4', 3),\n ('5', 4),\n ('8', 5),\n ('10', 6),\n ('11', 7),\n ('12', 8),\n ('13', 9),\n ('14', 10),\n ('15', 11),\n ('17', 12),\n ('18', 13),\n ('19', 14),\n ('20', 15),\n ('21', 16),\n ('25', 17),\n ('27', 18),\n ('29', 19)]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "list(item_index_old2new.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2445"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "## these are the items found in the kg (such as movie and book)\n",
    "item_set = set(item_index_old2new.values())\n",
    "len(item_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating():\n",
    "    file = 'data/' + DATASET + '/' + RATING_FILE_NAME[DATASET]\n",
    "    skip_line = SKIP_LINE[DATASET] - 1  # skip heading if needed\n",
    "\n",
    "    print('reading rating file ...')\n",
    "    item_set = set(item_index_old2new.values())  # len(item_set) is 2445 the total number of items\n",
    "\n",
    "    # change scaled ratings to binary: positive or negative\n",
    "    user_pos_ratings = dict()  \n",
    "    user_neg_ratings = dict()\n",
    "\n",
    "    # open the rating file\n",
    "    for i, line in enumerate(open(file, encoding='utf-8').readlines()):\n",
    "        if i == skip_line:  # skip heading if needed\n",
    "            continue\n",
    "        array = line.strip().split(SEP[DATASET])  # different dataset has different separators \n",
    "\n",
    "        # remove prefix and suffix quotation marks for book rating dataset\n",
    "        if DATASET == 'book':\n",
    "            array = list(map(lambda x: x[1:-1], array))\n",
    "        \n",
    "        # array user-SEP-movie-SEP-rating\n",
    "\n",
    "        item_index_old = array[1] # old index in the original rating file\n",
    "\n",
    "        # the following logic is that we only use the movie that showed up in the kg\n",
    "        # the item is not in the final item set\n",
    "        if item_index_old not in item_index_old2new:\n",
    "            continue  # skip the one that are not in the kg\n",
    "        #print(f'{item_index_old} in kg')\n",
    "        item_index = item_index_old2new[item_index_old]\n",
    "        #print(f'{item_index} is the new index in kg')\n",
    "\n",
    "        user_index_old = int(array[0])\n",
    "\n",
    "        rating = float(array[2])  # convert to pos and neg ratings\n",
    "        if rating >= THRESHOLD[DATASET]:\n",
    "            if user_index_old not in user_pos_ratings:\n",
    "                user_pos_ratings[user_index_old] = set()\n",
    "            user_pos_ratings[user_index_old].add(item_index)\n",
    "        else:\n",
    "            if user_index_old not in user_neg_ratings:\n",
    "                user_neg_ratings[user_index_old] = set()\n",
    "            user_neg_ratings[user_index_old].add(item_index)\n",
    "\n",
    "    #print(user_pos_ratings)\n",
    "    print('converting rating file ...')\n",
    "    writer = open('data/' + DATASET + '/ratings_final.txt', 'w', encoding='utf-8')\n",
    "    user_cnt = 0\n",
    "    user_index_old2new = dict()\n",
    "    for user_index_old, pos_item_set in user_pos_ratings.items():\n",
    "        if user_index_old not in user_index_old2new:\n",
    "            user_index_old2new[user_index_old] = user_cnt\n",
    "            user_cnt += 1\n",
    "        user_index = user_index_old2new[user_index_old]\n",
    "\n",
    "        for item in pos_item_set:\n",
    "            writer.write('%d\\t%d\\t1\\n' % (user_index, item)) # user_index tab item tab 1\n",
    "        unwatched_set = item_set - pos_item_set\n",
    "        # the following part logic is not quite clear\n",
    "        # see this issue: https://github.com/hwwang55/RippleNet/issues/18\n",
    "        # basically, the author's logic is if a movie rating is >=4 then, it's positive\n",
    "        # otherwise, remove the negative items from the item set if any and then\n",
    "        # random choose same amount of items as the positive ones as the negative ones\n",
    "        # note here 1 means interested 0 means not interested - low rating is also considered interestd by authors\n",
    "        if user_index_old in user_neg_ratings:\n",
    "            unwatched_set -= user_neg_ratings[user_index_old] # remove the negative ones\n",
    "        for item in np.random.choice(list(unwatched_set), size=len(pos_item_set), replace=False):  # random choose from the remaining set\n",
    "            writer.write('%d\\t%d\\t0\\n' % (user_index, item))\n",
    "    writer.close()\n",
    "    print('number of users: %d' % user_cnt)\n",
    "    print('number of items: %d' % len(item_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "reading rating file ...\nconverting rating file ...\nnumber of users: 6036\nnumber of items: 2445\n"
    }
   ],
   "source": [
    "convert_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kg():\n",
    "    print('converting kg file ...')\n",
    "    entity_cnt = len(entity_id2index)\n",
    "    relation_cnt = 0\n",
    "\n",
    "    writer = open('data/' + DATASET + '/kg_final.txt', 'w', encoding='utf-8')\n",
    "\n",
    "    files = []\n",
    "    if DATASET == 'movie':\n",
    "        files.append(open('data/' + DATASET + '/kg_part1_rehashed.txt', encoding='utf-8'))\n",
    "        files.append(open('data/' + DATASET + '/kg_part2_rehashed.txt', encoding='utf-8'))\n",
    "    else:\n",
    "        files.append(open('data/' + DATASET + '/kg_rehashed.txt', encoding='utf-8'))\n",
    "\n",
    "    for file in files:  # each line is a triplet head-TAB-relation-TAB-tail: 2451\tfilm.actor.film\t2452\n",
    "        for line in file:\n",
    "            array = line.strip().split('\\t')  # split by tab\n",
    "            head_old = array[0]  # head\n",
    "            relation_old = array[1]  # relation\n",
    "            tail_old = array[2]  # tail\n",
    "\n",
    "            if head_old not in entity_id2index:\n",
    "                entity_id2index[head_old] = entity_cnt\n",
    "                entity_cnt += 1\n",
    "            head = entity_id2index[head_old]\n",
    "\n",
    "            if tail_old not in entity_id2index:\n",
    "                entity_id2index[tail_old] = entity_cnt\n",
    "                entity_cnt += 1\n",
    "            tail = entity_id2index[tail_old]\n",
    "\n",
    "            if relation_old not in relation_id2index:\n",
    "                relation_id2index[relation_old] = relation_cnt\n",
    "                relation_cnt += 1\n",
    "            relation = relation_id2index[relation_old]\n",
    "\n",
    "            writer.write('%d\\t%d\\t%d\\n' % (head, relation, tail))\n",
    "\n",
    "    writer.close()  # the kg final: head-TAB-relationID-TAB-tail\n",
    "    print('number of entities (containing items): %d' % entity_cnt)\n",
    "    print('number of relations: %d' % relation_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "converting kg file ...\nnumber of entities (containing items): 182011\nnumber of relations: 12\n"
    }
   ],
   "source": [
    "convert_kg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followings are from the tools/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_np = np.loadtxt(\"./data/movie/ratings_final.txt\",  dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "753774"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "rating_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "753774"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "test_ratio = 0.2\n",
    "n_ratings = rating_np.shape[0]  # total number of ratings, movie 753774\n",
    "n_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "603020"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# get the test ratings indices 20%\n",
    "test_indices = np.random.choice(n_ratings,\n",
    "                                size=int(n_ratings * test_ratio),\n",
    "                                replace=False)\n",
    "train_indices = set(range(n_ratings)) - set(test_indices)  # train 80%\n",
    "len(train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "603020\n"
    }
   ],
   "source": [
    "# traverse training data, only keeping the users with positive ratings\n",
    "user_history_dict = dict()\n",
    "for i in train_indices:\n",
    "    user = rating_np[i][0]  # user\n",
    "    item = rating_np[i][1]  # item\n",
    "    rating = rating_np[i][2]  # rating 1 or 0\n",
    "    if rating == 1:  # positive rating\n",
    "        if user not in user_history_dict:\n",
    "            user_history_dict[user] = []\n",
    "        user_history_dict[user].append(item)\n",
    "\n",
    "# user_history_dict has all users and their corresponding positive rated items \n",
    "train_indices = [i for i in train_indices\n",
    "                    if rating_np[i][0] in user_history_dict]\n",
    "test_indices = [i for i in test_indices\n",
    "                if rating_np[i][0] in user_history_dict]\n",
    "print(len(train_indices))\n",
    "train_data = rating_np[train_indices]\n",
    "test_data = rating_np[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "753774"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# for the movie dataset, all users in the rating are kept\n",
    "total = len(train_data) + len(test_data)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  [0,\n   1669,\n   1419,\n   780,\n   1687,\n   1179,\n   670,\n   1696,\n   2082,\n   939,\n   1093,\n   1225,\n   341,\n   1624,\n   1760,\n   737,\n   1889,\n   1383,\n   624,\n   767]),\n (1,\n  [768,\n   1169,\n   1554,\n   1174,\n   1175,\n   669,\n   418,\n   930,\n   167,\n   1833,\n   1451,\n   1327,\n   309,\n   1974,\n   1207,\n   1342,\n   574,\n   2114,\n   1091,\n   837,\n   1225,\n   206,\n   975,\n   1361,\n   1875,\n   1883,\n   733,\n   737,\n   738,\n   226,\n   740,\n   231,\n   745,\n   1515,\n   748,\n   237,\n   1773,\n   2031,\n   1906,\n   379,\n   380,\n   767])]"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# first two items in the dict, user 0 and user 1\n",
    "list(user_history_dict.items())[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(1241995, 3)"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# itemID - relationID - itemID\n",
    "kg_np = np.loadtxt('./data/movie/kg_final.txt', dtype=np.int32)\n",
    "kg_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[2445,    0, 2446],\n       [2447,    1, 2448]], dtype=int32)"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "kg_np[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "182011 12\n"
    }
   ],
   "source": [
    "n_entity = len(set(kg_np[:, 0]) | set(kg_np[:, 2])) # unique number of entities\n",
    "n_relation = len(set(kg_np[:, 1]))  # unique number of relations\n",
    "print(n_entity, n_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "constructing knowledge graph ...\ndone\n"
    }
   ],
   "source": [
    "import collections\n",
    "print('constructing knowledge graph ...')\n",
    "kg = collections.defaultdict(list)\n",
    "for head, relation, tail in kg_np:\n",
    "    kg[head].append((tail, relation))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(2450, 2),\n (3264, 2),\n (2458, 3),\n (2533, 6),\n (5662, 2),\n (2955, 9),\n (2755, 10),\n (11559, 8)]"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "kg[4279] # 4279 is the head item followed by all (tail, relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(0,\n  [0,\n   1669,\n   1419,\n   780,\n   1687,\n   1179,\n   670,\n   1696,\n   2082,\n   939,\n   1093,\n   1225,\n   341,\n   1624,\n   1760,\n   737,\n   1889,\n   1383,\n   624,\n   767])]"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# user_history_dict has all users and their corresponding positive rated items \n",
    "list(user_history_dict.items())[:1]  # user 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n1\n"
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0,\n 1669,\n 1419,\n 780,\n 1687,\n 1179,\n 670,\n 1696,\n 2082,\n 939,\n 1093,\n 1225,\n 341,\n 1624,\n 1760,\n 737,\n 1889,\n 1383,\n 624,\n 767]"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# user_history_dict[user]\n",
    "user_history_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for user 0\n",
    "\n",
    "# the following shows the ripple set content\n",
    "# essentiall, the hop_0_tails becomes the hop_1_heads\n",
    "\n",
    "# user -> [(hop_0_heads, hop_0_relations, hop_0_tails),\n",
    "#          (hop_1_heads, hop_1_relations, hop_1_tails), ...]\n",
    "ripple_set = collections.defaultdict(list)\n",
    "user = 0\n",
    "n_hop = 2\n",
    "n_memory = 32 # size of ripple set - total of entities, set in main.py\n",
    "\n",
    "#for user in user_history_dict:\n",
    "for h in range(n_hop):\n",
    "    memories_h = []\n",
    "    memories_r = []\n",
    "    memories_t = []\n",
    "\n",
    "    if h == 0:  # first iteration initialization with all positive rated items\n",
    "        tails_of_last_hop = user_history_dict[user]\n",
    "    else:\n",
    "        # ripple_set[user][-1] means the previous (memories_h, memories_r, memories_t)\n",
    "        # [2] chooses memories_t from (memories_h, memories_r, memories_t)\n",
    "        tails_of_last_hop = ripple_set[user][-1][2]\n",
    "\n",
    "    for entity in tails_of_last_hop:\n",
    "        for tail_and_relation in kg[entity]:\n",
    "            memories_h.append(entity)\n",
    "            memories_r.append(tail_and_relation[1])\n",
    "            memories_t.append(tail_and_relation[0])\n",
    "\n",
    "    \"\"\"\n",
    "    if the current ripple set of the given user is empty,\n",
    "    we simply copy the ripple set of the last hop here\n",
    "    this won't happen for h = 0,\n",
    "    because only the items that appear in the KG have been selected\n",
    "    this only happens on 154 users in Book-Crossing dataset\n",
    "    (since both book dataset and the KG are sparse)\n",
    "    \"\"\"\n",
    "    if len(memories_h) == 0:\n",
    "        ripple_set[user].append(ripple_set[user][-1])\n",
    "    else:\n",
    "        # sample a fixed-size 1-hop memory for each user\n",
    "        # if memories_h <32 then, replace =True, may sample the same entity multiple times\n",
    "        replace = len(memories_h) < n_memory\n",
    "        indices = np.random.choice(\n",
    "            len(memories_h),\n",
    "            size=n_memory,\n",
    "            replace=replace\n",
    "            )\n",
    "        memories_h = [memories_h[i] for i in indices]\n",
    "        memories_r = [memories_r[i] for i in indices]\n",
    "        memories_t = [memories_t[i] for i in indices]\n",
    "        ripple_set[user].append(\n",
    "            (memories_h, memories_r, memories_t)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "defaultdict(list,\n            {0: [([1760,\n                1760,\n                0,\n                624,\n                780,\n                767,\n                1624,\n                341,\n                1419,\n                737,\n                1696,\n                2082,\n                341,\n                2082,\n                1419,\n                767,\n                767,\n                1624,\n                1225,\n                1687,\n                0,\n                1383,\n                939,\n                1383,\n                1225,\n                1669,\n                624,\n                341,\n                1093,\n                1687,\n                1383,\n                1383],\n               [8,\n                6,\n                7,\n                2,\n                7,\n                3,\n                2,\n                3,\n                7,\n                2,\n                8,\n                6,\n                7,\n                2,\n                8,\n                8,\n                6,\n                9,\n                2,\n                10,\n                7,\n                2,\n                2,\n                6,\n                7,\n                8,\n                7,\n                2,\n                9,\n                8,\n                7,\n                8],\n               [21745,\n                3721,\n                49232,\n                2466,\n                49449,\n                2458,\n                2861,\n                2458,\n                110070,\n                2450,\n                15528,\n                2533,\n                81300,\n                5662,\n                49232,\n                42255,\n                2477,\n                49884,\n                2450,\n                2755,\n                43078,\n                2535,\n                2450,\n                2477,\n                138768,\n                16074,\n                59038,\n                5662,\n                5264,\n                12008,\n                45333,\n                65980]),\n              ([5264,\n                49232,\n                2450,\n                43078,\n                2450,\n                2450,\n                49449,\n                21745,\n                43078,\n                2450,\n                5264,\n                2450,\n                21745,\n                49884,\n                5264,\n                2466,\n                2450,\n                5264,\n                2466,\n                2466,\n                2450,\n                2450,\n                2450,\n                2450,\n                49884,\n                16074,\n                49884,\n                42255,\n                49232,\n                49884,\n                2466,\n                12008],\n               [1,\n                5,\n                11,\n                5,\n                11,\n                11,\n                4,\n                5,\n                1,\n                11,\n                0,\n                11,\n                5,\n                1,\n                0,\n                11,\n                11,\n                1,\n                11,\n                11,\n                11,\n                11,\n                11,\n                11,\n                0,\n                5,\n                1,\n                5,\n                5,\n                1,\n                11,\n                5],\n               [1895,\n                24122,\n                107761,\n                78213,\n                176006,\n                130761,\n                780,\n                67854,\n                43079,\n                82494,\n                40843,\n                74742,\n                12710,\n                37899,\n                1072,\n                167776,\n                149267,\n                35503,\n                126499,\n                159237,\n                112684,\n                131790,\n                23706,\n                74742,\n                40852,\n                20913,\n                63510,\n                45471,\n                36326,\n                92599,\n                154081,\n                2392])]})"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "ripple_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitvenvvenv6c45b8dbf8fb4994a418e50f006017cc",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}